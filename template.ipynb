{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Digit Recognition Project"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "from data_utils import plot_images_with_labels, get_augmented_data\n",
    "from grid_search import get_best_pipeline, train_validate_test_split\n",
    "\n",
    "from sklearn.dummy import DummyClassifier\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.linear_model import SGDClassifier\n",
    "\n",
    "import copy\n",
    "\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### A. Data Exploration and Preprocessing\n",
    "1. Load and inspect the dataset: Discuss the meaning of the data and make sure that they are properly loaded. For example, are all data values sensible? Please include a figure or table to illustrate that the data is properly loaded.\n",
    "2. Perform the necessary steps to put the data in the right format for the machine learning algorithms. Explain the steps you take and why you take them. You are expected to  use all features and images â€“ there is no need for outlier pruning or other fancy preprocessing techniques.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Load and Inspect the Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load the dataset and plot some samples\n",
    "\n",
    "labeled_images = np.load(\"labeled_images.npy\")\n",
    "labeled_digits = np.load(\"labeled_digits.npy\")\n",
    "\n",
    "autograder_images = np.load(\"autograder_images.npy\")\n",
    "\n",
    "dataset = (labeled_images, labeled_digits)\n",
    "\n",
    "plot_images_with_labels(dataset, num_images=16)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Inspect the dataset\n",
    "\n",
    "# Inspect shapes of the datasets\n",
    "dataset_shape = labeled_images.shape\n",
    "labels_shape = labeled_digits.shape\n",
    "\n",
    "print(f\"Original dataset shapes: {labeled_images.shape}, {labeled_digits.shape}\")\n",
    "\n",
    "# Compute basic statistics for labeled_images\n",
    "images_min = np.min(labeled_images)\n",
    "images_max = np.max(labeled_images)\n",
    "images_mean = np.mean(labeled_images)\n",
    "images_std = np.std(labeled_images)\n",
    "\n",
    "labels_min = np.min(labeled_digits)\n",
    "labels_max = np.max(labeled_digits)\n",
    "labels_mean = np.mean(labeled_digits)\n",
    "labels_std = np.std(labeled_digits)\n",
    "labels_median = np.median(labeled_digits)\n",
    "\n",
    "# Check the unique labels in labeled_digits\n",
    "unique_labels = np.unique(labeled_digits)\n",
    "\n",
    "# Prepare a summary table\n",
    "summary_table = pd.DataFrame({\n",
    "    \"Attribute\": [\"Shape\", \"Min\", \"Max\", \"Mean\", \"Standard Deviation\", \"Median\", \"Unique Labels\"],\n",
    "    \"Images\": [str(dataset_shape), images_min, images_max, images_mean, images_std, None, None],\n",
    "    \"Labels\": [str(labels_shape), labels_min, labels_max, labels_mean, labels_std, labels_median, unique_labels.tolist()]\n",
    "})\n",
    "\n",
    "# Save the label data summary as a markdown file\n",
    "markdown_content = summary_table.to_markdown(index=False)\n",
    "\n",
    "# Save to a .md file\n",
    "file_path = \"report/data_summary.md\"\n",
    "with open(file_path, \"w\") as f:\n",
    "    f.write(markdown_content)\n",
    "\n",
    "summary_table"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Compute the distribution of labels\n",
    "label_counts = np.bincount(labeled_digits)\n",
    "\n",
    "# Create a DataFrame to summarize the distribution\n",
    "label_distribution = pd.DataFrame({\n",
    "    \"Label\": range(len(label_counts)),\n",
    "    \"Count\": label_counts,\n",
    "    \"Percentage\": (label_counts / len(labeled_digits)) * 100\n",
    "})\n",
    "\n",
    "# Save the label distribution as a markdown file\n",
    "markdown_content = label_distribution.to_markdown(index=False)\n",
    "\n",
    "# Save to a .md file\n",
    "file_path = \"report/label_distribution.md\"\n",
    "with open(file_path, \"w\") as f:\n",
    "    f.write(markdown_content)\n",
    "\n",
    "label_distribution"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Data Preprocessing and Augmentation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Augment the data and plot some samples\n",
    "augmented_dataset = get_augmented_data(dataset)\n",
    "plot_images_with_labels(dataset, num_images=16)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "augmented_images, augmented_labels = augmented_dataset\n",
    "\n",
    "# Inspect the dataset\n",
    "\n",
    "# Inspect shapes of the datasets\n",
    "dataset_shape = augmented_images.shape\n",
    "labels_shape = augmented_labels.shape\n",
    "\n",
    "print(f\"Augmented dataset shapes: {augmented_images.shape}, {augmented_labels.shape}\")\n",
    "\n",
    "# Compute basic statistics for augmented_images\n",
    "images_min = np.min(augmented_images)\n",
    "images_max = np.max(augmented_images)\n",
    "images_mean = np.mean(augmented_images)\n",
    "images_std = np.std(augmented_images)\n",
    "\n",
    "labels_min = np.min(augmented_labels)\n",
    "labels_max = np.max(augmented_labels)\n",
    "labels_mean = np.mean(augmented_labels)\n",
    "labels_std = np.std(augmented_labels)\n",
    "labels_median = np.median(augmented_labels)\n",
    "\n",
    "# Check the unique labels in labels\n",
    "unique_labels = np.unique(augmented_labels)\n",
    "\n",
    "# Prepare a summary table\n",
    "summary_table = pd.DataFrame({\n",
    "    \"Attribute\": [\"Shape\", \"Min\", \"Max\", \"Mean\", \"Standard Deviation\", \"Median\", \"Unique Labels\"],\n",
    "    \"Images\": [str(dataset_shape), images_min, images_max, images_mean, images_std, None, None],\n",
    "    \"Labels\": [str(labels_shape), labels_min, labels_max, labels_mean, labels_std, labels_median, unique_labels.tolist()]\n",
    "})\n",
    "\n",
    "# Save the label data summary as a markdown file\n",
    "markdown_content = summary_table.to_markdown(index=False)\n",
    "\n",
    "# Save to a .md file\n",
    "file_path = \"report/augmented_data_summary.md\"\n",
    "with open(file_path, \"w\") as f:\n",
    "    f.write(markdown_content)\n",
    "\n",
    "summary_table"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Compute the distribution of labels\n",
    "label_counts = np.bincount(augmented_labels)\n",
    "\n",
    "# Create a DataFrame to summarize the distribution\n",
    "label_distribution = pd.DataFrame({\n",
    "    \"Label\": range(len(label_counts)),\n",
    "    \"Count\": label_counts,\n",
    "    \"Percentage\": (label_counts / len(augmented_labels)) * 100\n",
    "})\n",
    "\n",
    "# Save the label distribution as a markdown file\n",
    "markdown_content = label_distribution.to_markdown(index=False)\n",
    "\n",
    "# Save to a .md file\n",
    "file_path = \"report/augmented_label_distribution.md\"\n",
    "with open(file_path, \"w\") as f:\n",
    "    f.write(markdown_content)\n",
    "\n",
    "label_distribution"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### B. Regression with Default Hyperparameters\n",
    "1. What is the simplest baseline model we should aim to beat? Or in other words, if you would have to make a guess for the label without knowing anything about the image, what would you guess? What is the accuracy of such a guess?\n",
    "2. Train the 4 models with default hyperparameters and fairly estimate their performance. Explain why the performance estimate is fair and how you estimated the performance.\n",
    "3. Submit your work to the autograder to check your work so far.\n",
    "\n",
    "### C. Tuning with GridSearch\n",
    "1. For all 4 models, use GridSearch (or any other strategy) to identify the best hyperparameters. Use a systematic way to tune hyperparameters that is reproducible. \n",
    "2. Explain your choice of hyperparameter search ranges and settings. Include sufficient details in the report so that another student can reproduce your experiment.\n",
    "3. Include a training curve (accuracy versus epochs) to illustrate how SGD converges.\n",
    "Explain why the performance estimate is fair for the tuned models and how you estimated the performance.\n",
    "4. Compare the performance of all models before and after hyperparameter tuning\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Dummy Classifier\n",
    "\n",
    "```python\n",
    "class sklearn.dummy.DummyClassifier(*, strategy='prior', random_state=None, constant=None)\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dummy = DummyClassifier(strategy=\"most_frequent\")\n",
    "\n",
    "dummy_results = get_best_pipeline(dataset, dummy, {})\n",
    "\n",
    "# Output test set accuracy\n",
    "print(f\"Test set accuracy: {dummy_results[2]:.4f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "aug_dummy = DummyClassifier(strategy=\"most_frequent\")\n",
    "\n",
    "aug_dummy_results = get_best_pipeline(dataset, aug_dummy, {}, data_aug=True)\n",
    "\n",
    "# Output test set accuracy\n",
    "print(f\"Test set accuracy: {aug_dummy_results[2]:.4f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Stochastic Gradient Descent Classifier with Logistic Loss Function\n",
    "\n",
    "```python\n",
    "class sklearn.linear_model.SGDClassifier(loss='hinge', *, penalty='l2', alpha=0.0001, l1_ratio=0.15, fit_intercept=True, max_iter=1000, tol=0.001, shuffle=True, verbose=0, epsilon=0.1, n_jobs=None, random_state=None, learning_rate='optimal', eta0=0.0, power_t=0.5, early_stopping=False, validation_fraction=0.1, n_iter_no_change=5, class_weight=None, warm_start=False, average=False)\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Default Hyperparamters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Without data augmentation\n",
    "\n",
    "default_SGD = SGDClassifier(loss=\"log_loss\")\n",
    "\n",
    "default_SGD_results = get_best_pipeline(dataset, default_SGD, {})\n",
    "\n",
    "# Output test set accuracy\n",
    "print(f\"Test set accuracy: {default_SGD_results[2]:.4f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# With data augmentation\n",
    "\n",
    "aug_default_SGD = SGDClassifier(loss=\"log_loss\")\n",
    "\n",
    "aug_default_SGD_results = get_best_pipeline(dataset, aug_default_SGD, {}, data_aug=True)\n",
    "\n",
    "# Output test set accuracy\n",
    "print(f\"Test set accuracy: {aug_default_SGD_results[2]:.4f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### GridSearch Cross-Validation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Without data augmentation\n",
    "\n",
    "gridsearch_SGD = SGDClassifier(\n",
    "        loss=\"log_loss\"\n",
    "    )\n",
    "\n",
    "\n",
    "param_grid = {\n",
    "    \"model__alpha\": [0.0001, 0.001, 0.01],\n",
    "    \"model__learning_rate\": [\"constant\", \"optimal\"],\n",
    "    \"model__eta0\": [0.001, 0.01, 0.1]\n",
    "}\n",
    "\n",
    "gridsearch_SGD_results = get_best_pipeline(dataset, gridsearch_SGD, param_grid)\n",
    "\n",
    "print(f\"Test set accuracy: {gridsearch_SGD_results[2]:.4f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# With data augmentation\n",
    "aug_gridsearch_SGD = SGDClassifier(\n",
    "        loss=\"log_loss\"\n",
    "    )\n",
    "\n",
    "\n",
    "param_grid = {\n",
    "    \"model__alpha\": [0.0001, 0.001, 0.01],\n",
    "    \"model__learning_rate\": [\"constant\", \"optimal\"],\n",
    "    \"model__eta0\": [0.001, 0.01, 0.1]\n",
    "}\n",
    "\n",
    "aug_gridsearch_SGD_results = get_best_pipeline(dataset, aug_gridsearch_SGD, param_grid, data_aug=True)\n",
    "\n",
    "# Output test set accuracy\n",
    "print(f\"Test set accuracy: {aug_gridsearch_SGD_results[2]:.4f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Plot the Training Curve"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_SGD_training_curve(best_params, dataset, max_epochs=1000, step=25, data_aug=False):\n",
    "    \"\"\"\n",
    "    Trains an SGDClassifier with the best parameters incrementally and plots the training curve (accuracy vs. epochs).\n",
    "\n",
    "    Args:\n",
    "        best_params (dict): The best hyperparameters for SGDClassifier.\n",
    "        dataset (tuple): A tuple containing (images, labels).\n",
    "        max_epochs (int, optional): Maximum number of epochs to train. Default is 1000.\n",
    "        step (int, optional): Step size for epoch increments. Default is 25.\n",
    "        data_aug (bool, optional): Whether to perform data augmentation. Default is False.\n",
    "\n",
    "    Returns:\n",
    "        best_model (SGDClassifier): The best-performing model observed during training.\n",
    "        None: Displays the training curve plot.\n",
    "    \"\"\"\n",
    "    # Unpack dataset\n",
    "    (X_train_val, y_train_val), (X_test, y_test) = train_validate_test_split(dataset, test_size=0.2)\n",
    "    \n",
    "    # Prepare data for training\n",
    "    if data_aug:\n",
    "        X_train_val, y_train_val = get_augmented_data((X_train_val, y_train_val))\n",
    "    X_train_val_flat = X_train_val.reshape(X_train_val.shape[0], -1)\n",
    "    X_test_flat = X_test.reshape(X_test.shape[0], -1)\n",
    "    classes = np.unique(y_train_val)  # Ensure all classes are passed for partial_fit\n",
    "\n",
    "    # Initialize the model with the best parameters\n",
    "    model = SGDClassifier(\n",
    "        loss=\"log_loss\",\n",
    "        alpha=best_params[\"model__alpha\"],\n",
    "        learning_rate=best_params[\"model__learning_rate\"],\n",
    "        eta0=best_params[\"model__eta0\"],\n",
    "        max_iter=1,  # Set max_iter to 1 for incremental updates\n",
    "        warm_start=True,  # Allows continuation of training\n",
    "        random_state=42,\n",
    "        tol=None,  # Ensure it doesn't stop early\n",
    "    )\n",
    "\n",
    "    # Track accuracies\n",
    "    train_accuracies = []\n",
    "    test_accuracies = []\n",
    "    epoch_range = range(1, max_epochs + 1, step)\n",
    "\n",
    "    # Variables to track the best model\n",
    "    best_model = None\n",
    "    best_test_accuracy = 0.0\n",
    "\n",
    "    for epoch in epoch_range:\n",
    "        # Incrementally train the model for `step` epochs\n",
    "        for _ in range(step):\n",
    "            model.partial_fit(X_train_val_flat, y_train_val, classes=classes)\n",
    "\n",
    "        # Compute accuracies\n",
    "        train_accuracy = model.score(X_train_val_flat, y_train_val)\n",
    "        test_accuracy = model.score(X_test_flat, y_test)\n",
    "\n",
    "        train_accuracies.append(train_accuracy)\n",
    "        test_accuracies.append(test_accuracy)\n",
    "\n",
    "        # Check if this model is the best so far\n",
    "        if test_accuracy > best_test_accuracy:\n",
    "            best_test_accuracy = test_accuracy\n",
    "            best_model = copy.deepcopy(model)  # Save the current best model\n",
    "\n",
    "    # Plot the training curve\n",
    "    plt.figure(figsize=(8, 6))\n",
    "    plt.plot(epoch_range, train_accuracies, label=\"Training Accuracy\", marker=\"o\")\n",
    "    plt.plot(epoch_range, test_accuracies, label=\"Test Accuracy\", marker=\"s\")\n",
    "    plt.xlabel(\"Number of Epochs\")\n",
    "    plt.ylabel(\"Accuracy\")\n",
    "    plt.title(\"Training Curve (Incremental Training): Accuracy vs. Epochs\")\n",
    "    plt.legend()\n",
    "    plt.grid()\n",
    "    plt.tight_layout()\n",
    "    plt.show()\n",
    "\n",
    "    print(f\"Best Test Accuracy: {best_test_accuracy:.4f}\")\n",
    "    return best_model\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "_, best_params, _  = gridsearch_SGD_results\n",
    "# Call the function with the best parameters and pipeline\n",
    "best_SGD = plot_SGD_training_curve(best_params, dataset)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "_, best_params, _  = aug_gridsearch_SGD_results\n",
    "# Call the function with the best parameters and pipeline\n",
    "best_aug_SGD = plot_SGD_training_curve(best_params, dataset, data_aug=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Decision Tree\n",
    "\n",
    "```python\n",
    "class sklearn.tree.DecisionTreeClassifier(*, criterion='gini', splitter='best', max_depth=None, min_samples_split=2, min_samples_leaf=1, min_weight_fraction_leaf=0.0, max_features=None, random_state=None, max_leaf_nodes=None, min_impurity_decrease=0.0, class_weight=None, ccp_alpha=0.0, monotonic_cst=None)\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Default Hyperparameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Without data augmentation\n",
    "\n",
    "default_DTC = DecisionTreeClassifier()\n",
    "\n",
    "default_DTC_results = get_best_pipeline(dataset, default_DTC, {})\n",
    "\n",
    "# Output test set accuracy\n",
    "print(f\"Test set accuracy: {default_DTC_results[2]:.4f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# With data augmentation\n",
    "\n",
    "aug_default_DTC = DecisionTreeClassifier()\n",
    "\n",
    "aug_default_DTC_results = get_best_pipeline(dataset, aug_default_DTC, {}, data_aug=True)\n",
    "\n",
    "# Output test set accuracy\n",
    "print(f\"Test set accuracy: {aug_default_DTC_results[2]:.4f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### GridSearch Cross-Validation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Without data augmentation\n",
    "\n",
    "gridsearch_DTC = DecisionTreeClassifier()\n",
    "\n",
    "\n",
    "param_grid = {\n",
    "    \"model__max_depth\": [5, 10, 20, None],\n",
    "    \"model__min_samples_split\": [2, 5, 10],\n",
    "    \"model__min_samples_leaf\": [1, 5, 10],\n",
    "    \"model__max_features\": [None, \"sqrt\", \"log2\"]\n",
    "}\n",
    "\n",
    "gridsearch_DTC_results = get_best_pipeline(dataset, gridsearch_DTC, param_grid)\n",
    "\n",
    "print(f\"Test set accuracy: {gridsearch_DTC_results[2]:.4f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# With data augmentation\n",
    "\n",
    "aug_gridsearch_DTC = DecisionTreeClassifier()\n",
    "\n",
    "\n",
    "param_grid = {\n",
    "    \"model__max_depth\": [5, 10, 20, None],\n",
    "    \"model__min_samples_split\": [2, 5, 10],\n",
    "    \"model__min_samples_leaf\": [1, 5, 10],\n",
    "    \"model__max_features\": [None, \"sqrt\", \"log2\"]\n",
    "}\n",
    "\n",
    "aug_gridsearch_DTC_results = get_best_pipeline(dataset, aug_gridsearch_DTC, param_grid, data_aug=True)\n",
    "\n",
    "print(f\"Test set accuracy: {aug_gridsearch_DTC_results[2]:.4f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### SVM Classifier\n",
    "\n",
    "```python \n",
    "class sklearn.svm.SVC(*, C=1.0, kernel='rbf', degree=3, gamma='scale', coef0=0.0, shrinking=True, probability=False, tol=0.001, cache_size=200, class_weight=None, verbose=False, max_iter=-1, decision_function_shape='ovr', break_ties=False, random_state=None)\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Default Hyperparameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Without data augmentation\n",
    "\n",
    "default_SVC = SVC(\n",
    "        C=1.0, kernel='rbf', gamma='scale' \n",
    "    )\n",
    "\n",
    "default_SVC_results = get_best_pipeline(dataset, default_SVC, {})\n",
    "\n",
    "# Output test set accuracy\n",
    "print(f\"Test set accuracy: {default_SVC_results[2]:.4f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# With data augmentation\n",
    "\n",
    "aug_default_SVC = SVC(\n",
    "        C=1.0, kernel='rbf', gamma='scale' \n",
    "    )\n",
    "\n",
    "aug_default_SVC_results = get_best_pipeline(dataset, aug_default_SVC, {}, data_aug=True)\n",
    "\n",
    "# Output test set accuracy\n",
    "print(f\"Test set accuracy: {aug_default_SVC_results[2]:.4f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### GridSearch Cross Validation "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Without data augmentation\n",
    "\n",
    "gridsearch_SVC = SVC(\n",
    "        C=1, kernel='rbf', gamma='scale'\n",
    "    )\n",
    "\n",
    "\n",
    "param_grid = {\n",
    "    \"model__C\": [1, 2, 3, 4, 5, 6, 7, 8, 9], \n",
    "    \"model__gamma\": [0.001, 0.1, 1, 10],\n",
    "    \"model__kernel\": ['rbf', 'poly', 'sigmoid'],\n",
    "    \"model__degree\": [2, 4, 8, 10]\n",
    "}\n",
    "\n",
    "gridsearch_SVC_results = get_best_pipeline(dataset, gridsearch_SVC, param_grid)\n",
    "\n",
    "print(f\"Test set accuracy: {gridsearch_SVC_results[2]:.4f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# With data augmentation\n",
    "\n",
    "aug_gridsearch_SVC = SVC(\n",
    "        C=1, kernel='rbf', gamma='scale'\n",
    "    )\n",
    "\n",
    "\n",
    "param_grid = {\n",
    "    \"model__C\": [1, 2, 3, 4, 5, 6, 7, 8, 9], \n",
    "    \"model__gamma\": [0.001, 0.1, 1, 10],\n",
    "    \"model__kernel\": ['rbf', 'poly', 'sigmoid'],\n",
    "    \"model__degree\": [2, 4, 8, 10]\n",
    "}\n",
    "\n",
    "\n",
    "aug_gridsearch_SVC_results = get_best_pipeline(dataset, aug_gridsearch_SVC, param_grid, data_aug=True)\n",
    "\n",
    "print(f\"Test set accuracy: {aug_gridsearch_SVC_results[2]:.4f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### (SVC) Prepare autograder submission"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "estimate = np.array(aug_gridsearch_SVC_results[2])\n",
    "prediction = aug_gridsearch_SVC_results[0].predict(autograder_images)\n",
    "# For example using something like:\n",
    "# prediction = my_super_duper_model.predict(autograder_images) \n",
    "\n",
    "result = np.append(estimate, prediction)\n",
    "\n",
    "# The code below will write your estimate and prediction to a file named autograder.txt\n",
    "# You will need to upload this file to the Vocareum autograder\n",
    "pd.DataFrame(result).to_csv(\"autograder_svc.txt\", index=False, header=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Prepare autograder submission"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In the autograder you will need to provide two things: 1) estimate of the accuracy of your model on unseen data, 2) the predictions on the autograder images. For the autograder images we only provide the images and not the class labels. Thus, you cannot compute the accuracy on this data yourself - you need to estimate that with labeled data that is provided (labeled_images, labeled_digits). We will calculate the accuracy for you on the autograder data and you will receive an automatic grade based on this. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "estimate = np.array([0.7]) # TODO Replace this with your estimate of the accuracy on new data\n",
    "prediction = np.array([-1] * len(autograder_images)) # TODO Replace this with your predictions of your best model\n",
    "# For example using something like:\n",
    "# prediction = my_super_duper_model.predict(autograder_images) \n",
    "\n",
    "result = np.append(estimate, prediction)\n",
    "\n",
    "# The code below will write your estimate and prediction to a file named autograder.txt\n",
    "# You will need to upload this file to the Vocareum autograder\n",
    "pd.DataFrame(result).to_csv(\"autograder.txt\", index=False, header=False)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.19"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
